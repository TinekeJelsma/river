{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines are an integral part of river. We encourage their usage and apply them in many of their examples.\n",
    "\n",
    "The `compose.Pipeline` contains all the logic for building and applying pipelines. A pipeline is essentially a list of estimators that are applied in sequence. The only requirement is that the first `n - 1` steps be transformers. The last step can be a regressor, a classifier, a clusterer, a transformer, etc. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:52.402747Z",
     "iopub.status.busy": "2020-11-20T00:42:52.401792Z",
     "iopub.status.idle": "2020-11-20T00:42:53.388918Z",
     "shell.execute_reply": "2020-11-20T00:42:53.387919Z"
    }
   },
   "outputs": [],
   "source": [
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import preprocessing\n",
    "from river import feature_extraction\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    feature_extraction.PolynomialExtender(),\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the `|` operator, as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:53.393829Z",
     "iopub.status.busy": "2020-11-20T00:42:53.392864Z",
     "iopub.status.idle": "2020-11-20T00:42:53.397047Z",
     "shell.execute_reply": "2020-11-20T00:42:53.396608Z"
    }
   },
   "outputs": [],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    feature_extraction.PolynomialExtender() |\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, equally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:53.402380Z",
     "iopub.status.busy": "2020-11-20T00:42:53.400798Z",
     "iopub.status.idle": "2020-11-20T00:42:53.402992Z",
     "shell.execute_reply": "2020-11-20T00:42:53.403419Z"
    }
   },
   "outputs": [],
   "source": [
    "model = preprocessing.StandardScaler() \n",
    "model |= feature_extraction.PolynomialExtender()\n",
    "model |= linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline has a `draw` method that can be used to visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:53.416408Z",
     "iopub.status.busy": "2020-11-20T00:42:53.412498Z",
     "iopub.status.idle": "2020-11-20T00:42:53.433301Z",
     "shell.execute_reply": "2020-11-20T00:42:53.433765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"217pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 217.28 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-328 213.281,-328 213.281,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\"><title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.641\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.641\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- StandardScaler -->\n",
       "<g id=\"node2\" class=\"node\"><title>StandardScaler</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.641\" cy=\"-234\" rx=\"82.5854\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.641\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">StandardScaler</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;StandardScaler -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>x&#45;&gt;StandardScaler</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.641,-287.697C104.641,-279.983 104.641,-270.712 104.641,-262.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.141,-262.104 104.641,-252.104 101.141,-262.104 108.141,-262.104\"/>\n",
       "</g>\n",
       "<!-- PolynomialExtender -->\n",
       "<g id=\"node3\" class=\"node\"><title>PolynomialExtender</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.641\" cy=\"-162\" rx=\"104.782\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.641\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">PolynomialExtender</text>\n",
       "</g>\n",
       "<!-- StandardScaler&#45;&gt;PolynomialExtender -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>StandardScaler&#45;&gt;PolynomialExtender</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.641,-215.697C104.641,-207.983 104.641,-198.712 104.641,-190.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.141,-190.104 104.641,-180.104 101.141,-190.104 108.141,-190.104\"/>\n",
       "</g>\n",
       "<!-- LinearRegression -->\n",
       "<g id=\"node4\" class=\"node\"><title>LinearRegression</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.641\" cy=\"-90\" rx=\"92.8835\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.641\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">LinearRegression</text>\n",
       "</g>\n",
       "<!-- PolynomialExtender&#45;&gt;LinearRegression -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>PolynomialExtender&#45;&gt;LinearRegression</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.641,-143.697C104.641,-135.983 104.641,-126.712 104.641,-118.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.141,-118.104 104.641,-108.104 101.141,-118.104 108.141,-118.104\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node5\" class=\"node\"><title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.641\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.641\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- LinearRegression&#45;&gt;y -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>LinearRegression&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.641,-71.6966C104.641,-63.9827 104.641,-54.7125 104.641,-46.1124\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.141,-46.1043 104.641,-36.1043 101.141,-46.1044 108.141,-46.1043\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fbef9d05518>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compose.Pipeline` inherits from `base.Estimator`, which means that it has a `learn_one` method. You would expect `learn_one` to update each estimator, but **that's not actually what happens**. Instead, the transformers are updated when `predict_one` (or `predict_proba_one` for that matter) is called. Indeed, in online machine learning, we can update the unsupervised parts of our model when a sample arrives. We don't have to wait for the ground truth to arrive in order to update unsupervised estimators that don't depend on it. In other words, in a pipeline, `learn_one` updates the supervised parts, whilst `predict_one` updates the unsupervised parts. It's important to be aware of this behavior, as it is quite different to what is done in other libraries that rely on batch machine learning.\n",
    "\n",
    "Here is a small example to illustrate the previous point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:53.439667Z",
     "iopub.status.busy": "2020-11-20T00:42:53.438513Z",
     "iopub.status.idle": "2020-11-20T00:42:53.444159Z",
     "shell.execute_reply": "2020-11-20T00:42:53.444562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ordinal_date': 736389,\n",
       "  'gallup': 43.843213,\n",
       "  'ipsos': 46.19925042857143,\n",
       "  'morning_consult': 48.318749,\n",
       "  'rasmussen': 44.104692,\n",
       "  'you_gov': 43.636914000000004},\n",
       " 43.75505)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import datasets\n",
    "\n",
    "dataset = datasets.TrumpApproval()\n",
    "x, y = next(iter(dataset))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us call `predict_one`, which will update each transformer, but won't update the linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:53.448983Z",
     "iopub.status.busy": "2020-11-20T00:42:53.448463Z",
     "iopub.status.idle": "2020-11-20T00:42:53.452664Z",
     "shell.execute_reply": "2020-11-20T00:42:53.453057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is nil because each weight of the linear regression is equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:53.458836Z",
     "iopub.status.busy": "2020-11-20T00:42:53.457896Z",
     "iopub.status.idle": "2020-11-20T00:42:53.460822Z",
     "shell.execute_reply": "2020-11-20T00:42:53.461223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'ordinal_date': 736389.0,\n",
       "             'gallup': 43.843213,\n",
       "             'ipsos': 46.19925042857143,\n",
       "             'morning_consult': 48.318749,\n",
       "             'rasmussen': 44.104692,\n",
       "             'you_gov': 43.636914000000004})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['StandardScaler'].means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the means of each feature have been updated, even though we called `predict_one` and not `learn_one`.\n",
    "\n",
    "Note that if you call `transform_one` with a pipeline who's last step is not a transformer, then the output from the last transformer (which is thus the penultimate step) will be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:53.467528Z",
     "iopub.status.busy": "2020-11-20T00:42:53.466848Z",
     "iopub.status.idle": "2020-11-20T00:42:53.469802Z",
     "shell.execute_reply": "2020-11-20T00:42:53.470215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ordinal_date': 0.0,\n",
       " 'gallup': 0.0,\n",
       " 'ipsos': 0.0,\n",
       " 'morning_consult': 0.0,\n",
       " 'rasmussen': 0.0,\n",
       " 'you_gov': 0.0,\n",
       " 'ordinal_date*ordinal_date': 0.0,\n",
       " 'gallup*ordinal_date': 0.0,\n",
       " 'ipsos*ordinal_date': 0.0,\n",
       " 'morning_consult*ordinal_date': 0.0,\n",
       " 'ordinal_date*rasmussen': 0.0,\n",
       " 'ordinal_date*you_gov': 0.0,\n",
       " 'gallup*gallup': 0.0,\n",
       " 'gallup*ipsos': 0.0,\n",
       " 'gallup*morning_consult': 0.0,\n",
       " 'gallup*rasmussen': 0.0,\n",
       " 'gallup*you_gov': 0.0,\n",
       " 'ipsos*ipsos': 0.0,\n",
       " 'ipsos*morning_consult': 0.0,\n",
       " 'ipsos*rasmussen': 0.0,\n",
       " 'ipsos*you_gov': 0.0,\n",
       " 'morning_consult*morning_consult': 0.0,\n",
       " 'morning_consult*rasmussen': 0.0,\n",
       " 'morning_consult*you_gov': 0.0,\n",
       " 'rasmussen*rasmussen': 0.0,\n",
       " 'rasmussen*you_gov': 0.0,\n",
       " 'you_gov*you_gov': 0.0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform_one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, you might want to connect a step to multiple steps. For instance, you might to extract different kinds of features from a single input. An elegant way to do this is to use a `compose.TransformerUnion`. Essentially, the latter is a list of transformers who's results will be merged into a single `dict` when `transform_one` is called. As an example let's say that we want to apply a `feature_extraction.RBFSampler` as well as the `feature_extraction.PolynomialExtender`. This may be done as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:53.478760Z",
     "iopub.status.busy": "2020-11-20T00:42:53.474967Z",
     "iopub.status.idle": "2020-11-20T00:42:53.494866Z",
     "shell.execute_reply": "2020-11-20T00:42:53.495279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"374pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 374.18 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-328 370.185,-328 370.185,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\"><title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.641\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.641\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- StandardScaler -->\n",
       "<g id=\"node2\" class=\"node\"><title>StandardScaler</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.641\" cy=\"-234\" rx=\"82.5854\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.641\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">StandardScaler</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;StandardScaler -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>x&#45;&gt;StandardScaler</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M200.641,-287.697C200.641,-279.983 200.641,-270.712 200.641,-262.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.141,-262.104 200.641,-252.104 197.141,-262.104 204.141,-262.104\"/>\n",
       "</g>\n",
       "<!-- PolynomialExtender -->\n",
       "<g id=\"node3\" class=\"node\"><title>PolynomialExtender</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.641\" cy=\"-162\" rx=\"104.782\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.641\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">PolynomialExtender</text>\n",
       "</g>\n",
       "<!-- StandardScaler&#45;&gt;PolynomialExtender -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>StandardScaler&#45;&gt;PolynomialExtender</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177.89,-216.411C165.309,-207.237 149.493,-195.704 135.78,-185.705\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"137.703,-182.776 127.561,-179.713 133.579,-188.432 137.703,-182.776\"/>\n",
       "</g>\n",
       "<!-- RBFSampler -->\n",
       "<g id=\"node4\" class=\"node\"><title>RBFSampler</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"296.641\" cy=\"-162\" rx=\"69.5877\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"296.641\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">RBFSampler</text>\n",
       "</g>\n",
       "<!-- StandardScaler&#45;&gt;RBFSampler -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>StandardScaler&#45;&gt;RBFSampler</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.391,-216.411C236.156,-207.103 252.251,-195.367 266.101,-185.268\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"268.367,-187.948 274.385,-179.228 264.242,-182.292 268.367,-187.948\"/>\n",
       "</g>\n",
       "<!-- LinearRegression -->\n",
       "<g id=\"node5\" class=\"node\"><title>LinearRegression</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.641\" cy=\"-90\" rx=\"92.8835\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.641\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">LinearRegression</text>\n",
       "</g>\n",
       "<!-- PolynomialExtender&#45;&gt;LinearRegression -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>PolynomialExtender&#45;&gt;LinearRegression</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.391,-144.411C140.064,-135.17 156.02,-123.536 169.802,-113.487\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"172.035,-116.19 178.053,-107.47 167.911,-110.534 172.035,-116.19\"/>\n",
       "</g>\n",
       "<!-- RBFSampler&#45;&gt;LinearRegression -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>RBFSampler&#45;&gt;LinearRegression</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M274.375,-144.765C261.715,-135.533 245.664,-123.83 231.773,-113.701\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.594,-110.697 223.452,-107.633 229.47,-116.353 233.594,-110.697\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node6\" class=\"node\"><title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.641\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.641\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- LinearRegression&#45;&gt;y -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>LinearRegression&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M200.641,-71.6966C200.641,-63.9827 200.641,-54.7125 200.641,-46.1124\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.141,-46.1043 200.641,-36.1043 197.141,-46.1044 204.141,-46.1043\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fbee8fcf828>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    (feature_extraction.PolynomialExtender() + feature_extraction.RBFSampler()) |\n",
    "    linear_model.LinearRegression()\n",
    ")\n",
    "\n",
    "model.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `+` symbol acts as a shorthand notation for creating a `compose.TransformerUnion`, which means that we could have declared the above pipeline as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T00:42:53.500574Z",
     "iopub.status.busy": "2020-11-20T00:42:53.500063Z",
     "iopub.status.idle": "2020-11-20T00:42:53.503596Z",
     "shell.execute_reply": "2020-11-20T00:42:53.504027Z"
    }
   },
   "outputs": [],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    compose.TransformerUnion(\n",
    "        feature_extraction.PolynomialExtender(),\n",
    "        feature_extraction.RBFSampler()\n",
    "    ) |\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines provide the benefit of removing a lot of cruft by taking care of tedious details for you. They also enable to clearly define what steps your model is made of. Finally, having your model in a single object means that you can move it around more easily. Note that you can include user-defined functions in a pipeline by using a `compose.FuncTransformer`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
